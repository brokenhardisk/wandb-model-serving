
version: '3.9'

services:
  model-server:
    image: tensorflow/serving
    command:
    - --model_name=animal_classifier
    - --model_base_path=/models/model/
    - --rest_api_port=8501
    ports:
    - 8501:8501
    tty: true
    volumes:
      - type: bind
        source: ./content/
        target: /models/
  
  backend:
    build: backend
    image: lab-backend
    container_name: backend_app
    ports:
      - "8080:80"
    environment:
      - UPLOAD_FOLDER=/data/images
      - MODEL_URL=http://model-server:8501/v1/models/animal_classifier:predict
    volumes:
      - ./data/images:/data/images
    depends_on:
      - model-server
  
  frontend:
    build: frontend
    image: lab-frontend
    container_name: streamlit_frontend
    ports:
      - "8502:8502"
    environment:
      - API_URL=http://backend
      - STREAMLIT_SERVER_PORT=${STREAMLIT_SERVER_PORT:-8502}
    depends_on:
      - backend